This document contains explanations of some of the EQI calculations supported by Ropoly, and some arguments for why we may or may not want to use them. I do not consider any EQI functions that are implemented in Ropoly but not listed here to be worth considering.

# EnVisen’s method

Ropoly usage: envisen-original

Calculates EQI as the percentage of gadgets from the original binary that do not survive at any location, plus “quality of movement.” Quality of movement is calculated based on each of the modified binary’s gadgets’ offsets relative to the closest gadgets with identical sequences in the original (not the offsets from the original binary’s gadgets to the modified binary’s—this makes a difference). Only the non-zero offsets are counted (gadgets at the zero offset are considered to have survived in place, and are not counted in the EQI). Quality of movement is calculated as (numberOfOffsets / numberOfMovedGadgets) * 100 * (1 - (standardDeviation(offsets)/highest_offset_count)). For clarification, standardDeviation(offsets) refers to the standard deviation of the counts of gadgets at each offset, not the standard deviation of the offsets in bytes.

EnVisen’s method has a couple of possible advantages.
* It is faster than any of the other methods described here. However, my understanding is that the other methods are fast enough. If speed ever becomes the deciding factor, I think it would be wise to look into possibilities for optimizing another method.
* Since it’s already used, no recalibration would be necessary. If we used any other formula, we would have to reevaluate what constitutes a “good” EQI—probably somewhere around 70-90 for the others listed here.

I don’t like this formula over all because I have a few problems with the quality of movement calculation.
* It is not scaled linearly by the number of moved gadgets. If the formula is supposed to measure how well a binary is scrambled, ignoring for now gadgets that are removed entirely and assuming that the movement of gadgets is not pathological, a scramble where more gadgets are moved and fewer survive in place should have a higher EQI than one where fewer gadgets are moved and more survive in place. Nothing in the formula makes this happen.
* Every offset is counted equally. An offset is a delta in bytes by which one or more gadgets from the original binary move to in the modified binary. Suppose a scramble of a 30,000-gadget binary has 10 different offsets, with 3000 gadgets from the original appearing at each. If you add an eleventh offset that just one gadget from the original binary appears at, that should have almost no effect on the quality of movement. The other formulas presented here would reflect this, but the EnVisen formula would not—the standard deviation of the gadget counts at each offset would spike while numberOfOffsets would increase significantly from 10 to 11, changing the overall quality of movement from 0.03333… to around 0.0256, a significant percentage difference. The very low quality of movement score to begin with in this example also shows a problem coming from the fact that the quality of movement does not scale linearly with the number of moved gadgets—a number as low as 0.0333 suggests that the even distribution of all gadgets over 10 different offsets in this example is worth almost nothing in terms of scrambling quality, which is clearly not true; it is much better than letting all gadgets survive in place, or even moving all gadgets by a single offset.
* This function can give an EQI over 100. If our EQI function can give a result outside of what is supposed to be an axiomatic bound, that seems indicative of underlying problems.
* This one is a minor nitpick, but the EnVisen function measures the offsets of moved gadgets from the modified binary to the original, rather than the other way around. It seems to me that EQI should reflect the “difficulty” of determining the modified binary given the original binary, rather than the other way around.
* A gadget could move by more than one offset. For example, if the gadget sequence “pop r12; ret” appears five times each in the original and modified binaries, then for each instance in one binary there are five offsets at which it can be found in the other. The EnVisen function only considers the closest offset for each. The purpose of using a complex EQI calculation that tries to assign a number to how well gadgets move rather than just checking if they move is to ensure that there isn’t pathological behavior with a disproportionately large number of gadgets moving together by a single offset, and arbitrarily checking only the closest offset for each gadget does not give any guarantee that pathological movement will be found. Checking only the closest offset may be part of what allows the EnVisen function to be so fast, and could be an optimization we decide we have to make if speed turns out to be more of an issue than expected, but I would rather do it intentionally after analyzing the benefits and drawbacks.

# Offset Intersections for Sets of Gadgets (Monte Carlo)

Ropoly usage: monte-carlo&min=int&max=int&trials=int

Generates trials sets of at least min and no more than max gadgets from the original binary. For each gadget, finds the set of offsets at which it can be found in the modified binary. Checks if the intersection between the sets of offsets is empty. The EQI is the percentage of these sets of sets for which the intersection is empty.

Each trial represents a simulated attack. The attack is considered to be impossible, even with a single piece of leaked information, if the gadgets cannot all be found at a single offset. The minimum and maximum numbers of gadgets represent the length of the attack. From what I have seen, the EQI increases very quickly as the number of gadgets is increased. For a good scramble, setting the minimum to 3 can easily result in a score well over 99.

Time needed seems to scale linearly, as one would expect, with number of trials, so there is a tradeoff between time and accuracy. Min and max seem to have very little effect on the amount of time needed. I have also implemented an exhaustive version of this method, but it seems too slow to be useful.

This method does not have any notion of strong survival. All offset intersections are considered equal, whether or not they include 0. I have a couple of ideas for how it might make sense to implement a version that does have a notion of strong survival, if desired.

# Most Shared Offset for Each Gadget

Ropoly usage: shared-offsets (treating strong and weak survival as the same), shared-offsets&multiple-handling=worst-only-envisen (taking into account strong survival)

For each gadget in the original binary, this method finds the offset (if any) at which it appears in the modified binary, which is shared with the most other gadgets. The gadget’s contribution to EQI is the percentage of gadgets that share that offset. When using the variation that treats strong and weak survival as the same, EQI is the average of all gadgets’ contributions to EQI.

Using the most shared offset for each gadget ensures that pathological behavior will not be outright ignored—if a gadget has an offset that it shares with, for example, 30% of gadgets in the binary, its contribution to EQI will be penalized at least based on that offset. However, it may not catch the exact degree. For example, suppose an original binary has 100 gadgets. 40 gadgets are offset by 0x100 in the modified binary, and a different 30 are offset by 0x200. EQI will take a 16-point hit for the 40 gadgets that move together and a 9-point hit for the 30 gadgets that move together. But what if 10 of the 40 that move by 0x100 and 10 of the 30 that move by 0x200 also move to 0x300? You can argue whether or not and to what degree this should be penalized. This function doesn’t penalize it—20 is less than 30 and less than 40, so it is not the most shared offset for any of the gadgets, and is ignored. Because only the most shared intersection is taken into account rather than all other gadgets that a gadget shares an offset with, this function (not taking into account strong survival) gives strictly higher EQIs than the offset intersection function.

This method can also be used taking into account strong survival. This way, if a gadget appears at offset 0 (that is, it survives in place), its contribution to EQI becomes 0. Otherwise, its EQI is the same as described above. This is equivalent to the EnVisen function, replacing the quality of movement function with the average contribution (as described in the previous paragraph) of each moved gadget to EQI, scaled by the proportion of moved gadgets.

Most shared offset with strong survival is my favorite right now. It differentiates between gadgets that move and gadgets that survive in place in the same way as EnVisen, taking into account our basic requirement that gadgets do not survive in place, while using a quality of movement calculation that makes intuitive sense and avoids all of the problems I that I have with EnVisen’s quality of movement calculation.